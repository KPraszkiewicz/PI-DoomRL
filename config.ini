[general]
name = XXX
version = 1

[learning]
algorithm = PPO
n_envs = 4
frame_skip = 4
rewards_shaping = False
total_timesteps = 100
continue = False
start_model = 
eval_freq = 4096

[game]
scenario = deathmatch_simple
combinated_buttons = True
n_bots = 8

[PPO]
learning_rate = 0.0001 
policy = CnnPolicy
custom_net = True
batch_size = 32
gamma = 0.99
n_steps = 4096
n_epochs = 3
gae_lambda = 0.95
clip_range = 0.2
clip_range_vf = None

[DQN]
learning_rate = 0.001 
policy = CnnPolicy
buffer_size = 100000
learning_starts = 5000
batch_size = 64
tau = 1.0
gamma = 0.99
train_freq = 4
gradient_steps = 1
target_update_interval = 100
exploration_fraction = 0.1
exploration_initial_eps = 1.0
exploration_final_eps = 0.05
max_grad_norm = 10
stats_window_size = 100
tensorboard_log = 